{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-26 13:10:52.459730: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-26 13:10:53.659963: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/vnl/miniconda3/envs/tf/lib/\n",
      "2022-12-26 13:10:53.660023: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/vnl/miniconda3/envs/tf/lib/\n",
      "2022-12-26 13:10:53.660027: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import keras \n",
    "\n",
    "\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.models import Sequential, Model, model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function reads in a .dcm file, checks the important fields for our device, and returns a numpy array\n",
    "# of just the imaging data\n",
    "def check_dicom(filename): \n",
    "    # todo\n",
    "    \n",
    "    print('Load file {} ...'.format(filename))\n",
    "    ds = pydicom.dcmread(filename)\n",
    "    \n",
    "    if (ds.Modality == 'DX') and (ds.BodyPartExamined=='CHEST') and (ds.PatientPosition in ['PA','AP']):\n",
    "        img = ds.pixel_array\n",
    "        return img\n",
    "    else:\n",
    "        print('This file does not match criteria of being a Chest X-Ray in PA or AP viewing position\\n')\n",
    "    \n",
    "    \n",
    "# This function takes the numpy array output by check_dicom and \n",
    "# runs the appropriate pre-processing needed for our model input\n",
    "def preprocess_image(img, img_mean, img_std, img_size): \n",
    "    # todo\n",
    "    \n",
    "    proc_img = ((img/255)-img_mean)/img_std\n",
    "    proc_img = resize(proc_img, img_size)\n",
    "    return proc_img\n",
    "\n",
    "# This function loads in our trained model w/ weights and compiles it \n",
    "def load_model(model_path, weight_path):\n",
    "    # todo\n",
    "    with open(model_path, 'r') as json_file:\n",
    "        json_savedModel= json_file.read() \n",
    "        \n",
    "    model = model_from_json(json_savedModel)\n",
    "    model.load_weights(weight_path)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# This function uses our device's threshold parameters to predict whether or not\n",
    "# the image shows the presence of pneumonia using our trained model\n",
    "def predict_image(model, img, thresh): \n",
    "    # todo    \n",
    "    prediction = model.predict(img) > thresh\n",
    "    \n",
    "    return prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-26 13:10:58.225830: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-26 13:10:58.253274: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-26 13:10:58.253514: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-26 13:10:58.254058: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-26 13:10:58.254765: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-26 13:10:58.254971: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-26 13:10:58.255151: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-26 13:10:59.136052: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-26 13:10:59.136251: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-26 13:10:59.136405: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-26 13:10:59.136692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:08:00.0, compute capability: 7.5\n",
      "2022-12-26 13:11:09.240553: W tensorflow/tsl/framework/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 9.00MiB (rounded to 9437184)requested by op AddV2\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2022-12-26 13:11:09.240588: I tensorflow/tsl/framework/bfc_allocator.cc:1034] BFCAllocator dump for GPU_0_bfc\n",
      "2022-12-26 13:11:09.240602: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (256): \tTotal Chunks: 22, Chunks in use: 22. 5.5KiB allocated for chunks. 5.5KiB in use in bin. 612B client-requested in use in bin.\n",
      "2022-12-26 13:11:09.240612: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (512): \tTotal Chunks: 2, Chunks in use: 2. 1.0KiB allocated for chunks. 1.0KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2022-12-26 13:11:09.240622: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1024): \tTotal Chunks: 4, Chunks in use: 4. 4.2KiB allocated for chunks. 4.2KiB in use in bin. 4.0KiB client-requested in use in bin.\n",
      "2022-12-26 13:11:09.240632: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2048): \tTotal Chunks: 2, Chunks in use: 1. 5.5KiB allocated for chunks. 2.0KiB in use in bin. 2.0KiB client-requested in use in bin.\n",
      "2022-12-26 13:11:09.240642: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4096): \tTotal Chunks: 1, Chunks in use: 1. 6.8KiB allocated for chunks. 6.8KiB in use in bin. 6.8KiB client-requested in use in bin.\n",
      "2022-12-26 13:11:09.240651: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-26 13:11:09.240659: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-26 13:11:09.240668: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-26 13:11:09.240676: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-26 13:11:09.240688: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (131072): \tTotal Chunks: 1, Chunks in use: 1. 144.0KiB allocated for chunks. 144.0KiB in use in bin. 144.0KiB client-requested in use in bin.\n",
      "2022-12-26 13:11:09.240699: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (262144): \tTotal Chunks: 3, Chunks in use: 1. 864.0KiB allocated for chunks. 288.0KiB in use in bin. 288.0KiB client-requested in use in bin.\n",
      "2022-12-26 13:11:09.240710: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (524288): \tTotal Chunks: 1, Chunks in use: 1. 576.0KiB allocated for chunks. 576.0KiB in use in bin. 576.0KiB client-requested in use in bin.\n",
      "2022-12-26 13:11:09.240720: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1048576): \tTotal Chunks: 3, Chunks in use: 1. 3.38MiB allocated for chunks. 1.12MiB in use in bin. 1.12MiB client-requested in use in bin.\n",
      "2022-12-26 13:11:09.240728: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2097152): \tTotal Chunks: 2, Chunks in use: 2. 4.50MiB allocated for chunks. 4.50MiB in use in bin. 4.50MiB client-requested in use in bin.\n",
      "2022-12-26 13:11:09.240736: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4194304): \tTotal Chunks: 3, Chunks in use: 1. 13.50MiB allocated for chunks. 4.50MiB in use in bin. 4.50MiB client-requested in use in bin.\n",
      "2022-12-26 13:11:09.240744: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8388608): \tTotal Chunks: 2, Chunks in use: 2. 23.81MiB allocated for chunks. 23.81MiB in use in bin. 18.00MiB client-requested in use in bin.\n",
      "2022-12-26 13:11:09.240750: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-26 13:11:09.240757: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-26 13:11:09.240763: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-26 13:11:09.240772: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-26 13:11:09.240780: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-26 13:11:09.240790: I tensorflow/tsl/framework/bfc_allocator.cc:1057] Bin for 9.00MiB was 8.00MiB, Chunk State: \n",
      "2022-12-26 13:11:09.240797: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 49020928\n",
      "2022-12-26 13:11:09.240808: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd7e0000000 of size 256 next 1\n",
      "2022-12-26 13:11:09.240813: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd7e0000100 of size 1280 next 2\n",
      "2022-12-26 13:11:09.240819: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd7e0000600 of size 256 next 3\n",
      "2022-12-26 13:11:09.240824: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd7e0000700 of size 256 next 4\n",
      "2022-12-26 13:11:09.240829: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd7e0000800 of size 256 next 6\n",
      "2022-12-26 13:11:09.240835: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd7e0000900 of size 256 next 7\n",
      "2022-12-26 13:11:09.240840: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd7e0000a00 of size 256 next 5\n",
      "2022-12-26 13:11:09.240845: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd7e0000b00 of size 256 next 8\n",
      "2022-12-26 13:11:09.240850: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd7e0000c00 of size 256 next 13\n",
      "2022-12-26 13:11:09.240856: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd7e0000d00 of size 256 next 11\n",
      "2022-12-26 13:11:09.240864: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd7e0000e00 of size 256 next 12\n",
      "2022-12-26 13:11:09.240872: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd7e0000f00 of size 512 next 16\n",
      "2022-12-26 13:11:09.240881: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd7e0001100 of size 256 next 17\n",
      "2022-12-26 13:11:09.240889: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd7e0001200 of size 256 next 20\n",
      "2022-12-26 13:11:09.240896: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd7e0001300 of size 512 next 23\n",
      "2022-12-26 13:11:09.240904: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd7e0001500 of size 256 next 21\n",
      "2022-12-26 13:11:09.240912: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd7e0001600 of size 256 next 22\n",
      "2022-12-26 13:11:09.240919: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd7e0001700 of size 1024 next 26\n",
      "2022-12-26 13:11:09.240927: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd7e0001b00 of size 256 next 27\n",
      "2022-12-26 13:11:09.240934: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd7e0001c00 of size 256 next 30\n",
      "2022-12-26 13:11:09.240942: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd7e0001d00 of size 1024 next 33\n",
      "2022-12-26 13:11:09.240949: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd7e0002100 of size 1024 next 36\n",
      "2022-12-26 13:11:09.240957: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd7e0002500 of size 256 next 31\n",
      "2022-12-26 13:11:09.240965: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd7e0002600 of size 256 next 32\n",
      "2022-12-26 13:11:09.240973: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd7e0002700 of size 2048 next 38\n",
      "2022-12-26 13:11:09.240981: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd7e0002f00 of size 256 next 39\n",
      "2022-12-26 13:11:09.240988: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd7e0003000 of size 256 next 42\n",
      "2022-12-26 13:11:09.240996: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd7e0003100 of size 256 next 43\n",
      "2022-12-26 13:11:09.241004: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd7e0003200 of size 256 next 44\n",
      "2022-12-26 13:11:09.241012: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7fd7e0003300 of size 3584 next 9\n",
      "2022-12-26 13:11:09.241019: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd7e0004100 of size 6912 next 10\n",
      "2022-12-26 13:11:09.241023: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7fd7e0005c00 of size 294912 next 15\n",
      "2022-12-26 13:11:09.241027: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd7e004dc00 of size 147456 next 14\n",
      "2022-12-26 13:11:09.241031: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7fd7e0071c00 of size 294912 next 19\n",
      "2022-12-26 13:11:09.241036: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd7e00b9c00 of size 294912 next 18\n",
      "2022-12-26 13:11:09.241040: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7fd7e0101c00 of size 1179648 next 25\n",
      "2022-12-26 13:11:09.241044: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd7e0221c00 of size 589824 next 24\n",
      "2022-12-26 13:11:09.241049: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7fd7e02b1c00 of size 1179648 next 29\n",
      "2022-12-26 13:11:09.241054: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd7e03d1c00 of size 1179648 next 28\n",
      "2022-12-26 13:11:09.241059: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7fd7e04f1c00 of size 4718592 next 35\n",
      "2022-12-26 13:11:09.241063: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd7e0971c00 of size 2359296 next 34\n",
      "2022-12-26 13:11:09.241067: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd7e0bb1c00 of size 2359296 next 37\n",
      "2022-12-26 13:11:09.241070: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7fd7e0df1c00 of size 4718592 next 41\n",
      "2022-12-26 13:11:09.241074: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd7e1271c00 of size 4718592 next 40\n",
      "2022-12-26 13:11:09.241078: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd7e16f1c00 of size 9437184 next 45\n",
      "2022-12-26 13:11:09.241082: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7fd7e1ff1c00 of size 15524864 next 18446744073709551615\n",
      "2022-12-26 13:11:09.241087: I tensorflow/tsl/framework/bfc_allocator.cc:1095]      Summary of in-use Chunks by size: \n",
      "2022-12-26 13:11:09.241092: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 22 Chunks of size 256 totalling 5.5KiB\n",
      "2022-12-26 13:11:09.241097: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 512 totalling 1.0KiB\n",
      "2022-12-26 13:11:09.241101: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 1024 totalling 3.0KiB\n",
      "2022-12-26 13:11:09.241105: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2022-12-26 13:11:09.241109: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 2048 totalling 2.0KiB\n",
      "2022-12-26 13:11:09.241114: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 6912 totalling 6.8KiB\n",
      "2022-12-26 13:11:09.241118: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 147456 totalling 144.0KiB\n",
      "2022-12-26 13:11:09.241122: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 294912 totalling 288.0KiB\n",
      "2022-12-26 13:11:09.241127: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 589824 totalling 576.0KiB\n",
      "2022-12-26 13:11:09.241131: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1179648 totalling 1.12MiB\n",
      "2022-12-26 13:11:09.241136: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 2359296 totalling 4.50MiB\n",
      "2022-12-26 13:11:09.241140: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 4718592 totalling 4.50MiB\n",
      "2022-12-26 13:11:09.241145: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 9437184 totalling 9.00MiB\n",
      "2022-12-26 13:11:09.241149: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 15524864 totalling 14.81MiB\n",
      "2022-12-26 13:11:09.241154: I tensorflow/tsl/framework/bfc_allocator.cc:1102] Sum Total of in-use chunks: 34.93MiB\n",
      "2022-12-26 13:11:09.241158: I tensorflow/tsl/framework/bfc_allocator.cc:1104] total_region_allocated_bytes_: 49020928 memory_limit_: 49020928 available bytes: 0 curr_region_allocation_bytes_: 98041856\n",
      "2022-12-26 13:11:09.241166: I tensorflow/tsl/framework/bfc_allocator.cc:1110] Stats: \n",
      "Limit:                        49020928\n",
      "InUse:                        36631040\n",
      "MaxInUse:                     36631296\n",
      "NumAllocs:                          80\n",
      "MaxAllocSize:                 15524864\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-12-26 13:11:09.241172: W tensorflow/tsl/framework/bfc_allocator.cc:492] ***_**__***_________**********_________*************************************************xxxxxxxxxxxx\n",
      "2022-12-26 13:11:09.241981: W tensorflow/core/framework/op_kernel.cc:1818] RESOURCE_EXHAUSTED: failed to allocate memory\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:AddV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m img_mean \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;66;03m# loads the mean image value they used during training preprocessing\u001b[39;00m\n\u001b[1;32m      8\u001b[0m img_std \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# loads the std dev image value they used during training preprocessing\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m my_model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#loads model\u001b[39;00m\n\u001b[1;32m     11\u001b[0m thresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m \u001b[38;5;66;03m#loads the threshold they chose for model classification \u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# use the .dcm files to test your prediction\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 31\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_path, weight_path)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(model_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m json_file:\n\u001b[1;32m     29\u001b[0m     json_savedModel\u001b[38;5;241m=\u001b[39m json_file\u001b[38;5;241m.\u001b[39mread() \n\u001b[0;32m---> 31\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_from_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_savedModel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m model\u001b[38;5;241m.\u001b[39mload_weights(weight_path)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/saving/legacy/model_config.py:109\u001b[0m, in \u001b[0;36mmodel_from_json\u001b[0;34m(json_string, custom_objects)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m\"\"\"Parses a JSON model configuration string and returns a model instance.\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03mUsage:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    A Keras model instance (uncompiled).\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    106\u001b[0m     deserialize_from_json,\n\u001b[1;32m    107\u001b[0m )\n\u001b[0;32m--> 109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize_from_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/layers/serialization.py:275\u001b[0m, in \u001b[0;36mdeserialize_from_json\u001b[0;34m(json_string, custom_objects)\u001b[0m\n\u001b[1;32m    269\u001b[0m populate_deserializable_objects()\n\u001b[1;32m    270\u001b[0m config \u001b[38;5;241m=\u001b[39m json_utils\u001b[38;5;241m.\u001b[39mdecode_and_deserialize(\n\u001b[1;32m    271\u001b[0m     json_string,\n\u001b[1;32m    272\u001b[0m     module_objects\u001b[38;5;241m=\u001b[39mLOCAL\u001b[38;5;241m.\u001b[39mALL_OBJECTS,\n\u001b[1;32m    273\u001b[0m     custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m    274\u001b[0m )\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/layers/serialization.py:252\u001b[0m, in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;124;03m\"\"\"Instantiates a layer from a config dictionary.\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m```\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    251\u001b[0m populate_deserializable_objects()\n\u001b[0;32m--> 252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mserialization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLOCAL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mALL_OBJECTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprintable_module_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlayer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/saving/legacy/serialization.py:517\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom_objects\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m arg_spec\u001b[38;5;241m.\u001b[39margs:\n\u001b[1;32m    516\u001b[0m     tlco \u001b[38;5;241m=\u001b[39m object_registration\u001b[38;5;241m.\u001b[39m_THREAD_LOCAL_CUSTOM_OBJECTS\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[0;32m--> 517\u001b[0m     deserialized_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcls_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mobject_registration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_GLOBAL_CUSTOM_OBJECTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtlco\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m object_registration\u001b[38;5;241m.\u001b[39mCustomObjectScope(custom_objects):\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/sequential.py:478\u001b[0m, in \u001b[0;36mSequential.from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    476\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_config \u001b[38;5;129;01min\u001b[39;00m layer_configs:\n\u001b[0;32m--> 478\u001b[0m     layer \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    481\u001b[0m     model\u001b[38;5;241m.\u001b[39madd(layer)\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(saving_lib\u001b[38;5;241m.\u001b[39m_SAVING_V3_ENABLED, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/layers/serialization.py:252\u001b[0m, in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;124;03m\"\"\"Instantiates a layer from a config dictionary.\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m```\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    251\u001b[0m populate_deserializable_objects()\n\u001b[0;32m--> 252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mserialization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLOCAL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mALL_OBJECTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprintable_module_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlayer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/saving/legacy/serialization.py:517\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom_objects\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m arg_spec\u001b[38;5;241m.\u001b[39margs:\n\u001b[1;32m    516\u001b[0m     tlco \u001b[38;5;241m=\u001b[39m object_registration\u001b[38;5;241m.\u001b[39m_THREAD_LOCAL_CUSTOM_OBJECTS\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[0;32m--> 517\u001b[0m     deserialized_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcls_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mobject_registration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_GLOBAL_CUSTOM_OBJECTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtlco\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m object_registration\u001b[38;5;241m.\u001b[39mCustomObjectScope(custom_objects):\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py:3114\u001b[0m, in \u001b[0;36mModel.from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   3107\u001b[0m functional_model_keys \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3108\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3109\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayers\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3110\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_layers\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3111\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_layers\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3112\u001b[0m ]\n\u001b[1;32m   3113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(key \u001b[38;5;129;01min\u001b[39;00m config \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m functional_model_keys):\n\u001b[0;32m-> 3114\u001b[0m     inputs, outputs, layers \u001b[38;5;241m=\u001b[39m \u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreconstruct_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\n\u001b[1;32m   3116\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3117\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\n\u001b[1;32m   3118\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs, outputs\u001b[38;5;241m=\u001b[39moutputs, name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3119\u001b[0m     )\n\u001b[1;32m   3120\u001b[0m     functional\u001b[38;5;241m.\u001b[39mconnect_ancillary_layers(model, layers)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py:1482\u001b[0m, in \u001b[0;36mreconstruct_from_config\u001b[0;34m(config, custom_objects, created_layers)\u001b[0m\n\u001b[1;32m   1480\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m layer_nodes:\n\u001b[1;32m   1481\u001b[0m     node_data \u001b[38;5;241m=\u001b[39m layer_nodes[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 1482\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mprocess_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_data\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1483\u001b[0m         layer_nodes\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   1484\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1485\u001b[0m         \u001b[38;5;66;03m# If a node can't be processed, stop processing the\u001b[39;00m\n\u001b[1;32m   1486\u001b[0m         \u001b[38;5;66;03m# nodes of the current layer to maintain node ordering.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py:1422\u001b[0m, in \u001b[0;36mreconstruct_from_config.<locals>.process_node\u001b[0;34m(layer, node_data)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m layer\u001b[38;5;241m.\u001b[39m_preserve_input_structure_in_config:\n\u001b[1;32m   1419\u001b[0m     input_tensors \u001b[38;5;241m=\u001b[39m base_layer_utils\u001b[38;5;241m.\u001b[39munnest_if_single_tensor(\n\u001b[1;32m   1420\u001b[0m         input_tensors\n\u001b[1;32m   1421\u001b[0m     )\n\u001b[0;32m-> 1422\u001b[0m output_tensors \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;66;03m# Update node index map.\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m output_index \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(output_tensors)[\n\u001b[1;32m   1426\u001b[0m     \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1427\u001b[0m ]\u001b[38;5;241m.\u001b[39m_keras_history\u001b[38;5;241m.\u001b[39mnode_index\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/backend.py:2100\u001b[0m, in \u001b[0;36mRandomGenerator.random_uniform\u001b[0;34m(self, shape, minval, maxval, dtype, nonce)\u001b[0m\n\u001b[1;32m   2098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nonce:\n\u001b[1;32m   2099\u001b[0m         seed \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mstateless_fold_in(seed, nonce)\n\u001b[0;32m-> 2100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstateless_uniform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mminval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mminval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaxval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2106\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\n\u001b[1;32m   2108\u001b[0m     shape\u001b[38;5;241m=\u001b[39mshape,\n\u001b[1;32m   2109\u001b[0m     minval\u001b[38;5;241m=\u001b[39mminval,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2112\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_legacy_seed(),\n\u001b[1;32m   2113\u001b[0m )\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:AddV2]"
     ]
    }
   ],
   "source": [
    "test_dicoms = ['test1.dcm','test2.dcm','test3.dcm','test4.dcm','test5.dcm','test6.dcm']\n",
    "\n",
    "model_path = \"my_model.json\" #path to saved model\n",
    "weight_path = \"{}_my_model.best.hdf5\".format('xray_class')#path to saved best weights\n",
    "\n",
    "IMG_SIZE=(1,224,224,3) # This might be different if you did not use vgg16\n",
    "img_mean = 0 # loads the mean image value they used during training preprocessing\n",
    "img_std = 1 # loads the std dev image value they used during training preprocessing\n",
    "\n",
    "my_model = load_model(model_path, weight_path) #loads model\n",
    "thresh = 0.1 #loads the threshold they chose for model classification \n",
    "\n",
    "# use the .dcm files to test your prediction\n",
    "for i in test_dicoms:\n",
    "    \n",
    "    img = np.array([])\n",
    "    img = check_dicom(i)\n",
    "    \n",
    "    if img is None:\n",
    "        continue\n",
    "        \n",
    "    img_proc = preprocess_image(img,img_mean,img_std,IMG_SIZE)\n",
    "    pred = predict_image(my_model,img_proc,thresh)\n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
